{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXIq/WW7wOjTPka+xiqEdM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niksom406/Learning_NLP/blob/main/Lemmatization_Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ab1f2ca"
      },
      "source": [
        "## Lemmatization and WordNet Lemmatization with NLTK\n",
        "\n",
        "**Lemmatization** is the process of reducing words to their base or dictionary form, known as the lemma. Unlike stemming, which often just chops off suffixes, lemmatization considers the context and uses a vocabulary and morphological analysis of words to return the base or dictionary form of a word, which is known as the **lemma**. For example, the words \"running\", \"ran\", and \"runs\" all have the same lemma: \"run\".\n",
        "\n",
        "**WordNet Lemmatization** is a specific type of lemmatization that uses the **WordNet** lexical database. WordNet is a large database of English words linked together by their semantic relationships (like synonyms, antonyms, hyponyms, etc.). The NLTK library provides access to WordNet and includes a lemmatizer that leverages this database.\n",
        "\n",
        "Here's how WordNet Lemmatization typically works in NLTK:\n",
        "\n",
        "1.  **Import necessary modules:** You need to import `WordNetLemmatizer` from `nltk.stem` and potentially `wordnet` from `nltk.corpus`.\n",
        "2.  **Initialize the lemmatizer:** Create an instance of the `WordNetLemmatizer`.\n",
        "3.  **Lemmatize the word:** Use the `lemmatize()` method of the lemmatizer object. This method often takes the word and an optional part-of-speech (POS) tag as arguments. The POS tag is important because the lemma of a word can depend on its grammatical role in a sentence (e.g., \"lead\" as a noun vs. \"lead\" as a verb). WordNet requires specific POS tags ('n' for noun, 'v' for verb, 'a' for adjective, 'r' for adverb). If no POS tag is provided, it defaults to noun.\n",
        "\n",
        "**Key advantages of WordNet Lemmatization:**\n",
        "\n",
        "*   **More accurate:** It often provides a more accurate lemma than simple stemming because it considers the word's meaning and context through the WordNet database.\n",
        "*   **Handles irregular forms:** It can handle irregular plurals (e.g., \"mice\" -> \"mouse\") and irregular verb conjugations (e.g., \"went\" -> \"go\") effectively.\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "*   **Requires POS tagging:** For optimal results, you usually need to perform part-of-speech tagging on your text before lemmatization to provide the correct POS tag to the lemmatizer.\n",
        "*   **WordNet coverage:** While extensive, WordNet doesn't contain every word or every possible form of a word.\n",
        "\n",
        "In summary, WordNet Lemmatization with NLTK is a powerful technique for reducing words to their base forms by leveraging the rich information in the WordNet lexical database, resulting in more accurate and contextually relevant lemmas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "jMOgAmSaaCvE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "id": "GXjTWN7udRmk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3WeogbQaVJ6",
        "outputId": "5f5e8e2b-a067-4a21-d1b3-edcb91c450e6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "tvpQTMMXaHxH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"mice\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pcM2dyNQaLoF",
        "outputId": "f0838462-f847-4d82-a8f0-1c0891750f44"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mouse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"going\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CUiXnVKUaQWj",
        "outputId": "b6e8277c-e86c-4918-dc0f-f631a55d5ff1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'going'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "POS- Noun - n\n",
        "POS- Verb - v\n",
        "POS- Adjective - a\n",
        "POS- Adverb - r\n",
        "'''\n",
        "lemmatizer.lemmatize(\"going\", pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HtrYa2jlaZ7i",
        "outputId": "60432689-16e0-41ca-86a7-f98b7baf25cd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"better\", pos='a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qJ5c5Jsiakkd",
        "outputId": "a1f2a3cc-b901-4315-8d23-b4faeb89b4d7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"ran\", pos='r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hHVJ4Pweam9u",
        "outputId": "553eaf32-6538-40ea-86da-9766bfeedac1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ran'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['history', 'historical', 'historically', 'historian', 'histories', 'believe', 'believer', 'believing', 'believed', 'beautiful', 'beauty', 'beautify', 'beautifying', 'run', 'running','eats','eating','eaten','writing','written','programming','programs','finally','finalized']"
      ],
      "metadata": {
        "id": "EXfwIi30apvc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + ' ---> ' + lemmatizer.lemmatize(word, pos = \"v\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWYNj8s1a6oS",
        "outputId": "ea3845a2-bc52-4bec-e4a6-3c460d7a7e59"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history ---> history\n",
            "historical ---> historical\n",
            "historically ---> historically\n",
            "historian ---> historian\n",
            "histories ---> histories\n",
            "believe ---> believe\n",
            "believer ---> believer\n",
            "believing ---> believe\n",
            "believed ---> believe\n",
            "beautiful ---> beautiful\n",
            "beauty ---> beauty\n",
            "beautify ---> beautify\n",
            "beautifying ---> beautify\n",
            "run ---> run\n",
            "running ---> run\n",
            "eats ---> eat\n",
            "eating ---> eat\n",
            "eaten ---> eat\n",
            "writing ---> write\n",
            "written ---> write\n",
            "programming ---> program\n",
            "programs ---> program\n",
            "finally ---> finally\n",
            "finalized ---> finalize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('fairly'), lemmatizer.lemmatize('sportingly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyrgesCibMab",
        "outputId": "2cdf383d-8a76-467d-b5bc-c5ecf77e6c6a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fairly', 'sportingly')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('going',pos = \"v\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E3vJj_s8cnBi",
        "outputId": "d7ba9fd5-e57b-45d4-fab9-b69d170b3142"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "kzdfnPXVcoVk"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfmtJZLIeiFC",
        "outputId": "9c53644f-d9de-4933-e247-a009233535f2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Donald Trump has a devoted following\".split()"
      ],
      "metadata": {
        "id": "jbrjdErner20"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_and_tags = nltk.pos_tag(sentence)\n",
        "words_and_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq8AUxZ8e2Er",
        "outputId": "885b57e0-301f-4a9c-a6b8-6dc94c747dd8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Donald', 'NNP'),\n",
              " ('Trump', 'NNP'),\n",
              " ('has', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('devoted', 'VBN'),\n",
              " ('following', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word,tag in words_and_tags:\n",
        "  lemma = lemmatizer.lemmatize(word, pos = get_wordnet_pos(tag))\n",
        "  print(word+\" ---> \"+lemma)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkf5zhdue5pE",
        "outputId": "7923c1f8-59e9-449a-da89-46053fc85316"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Donald ---> Donald\n",
            "Trump ---> Trump\n",
            "has ---> have\n",
            "a ---> a\n",
            "devoted ---> devote\n",
            "following ---> following\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The cat was following the bird as it flew by\".split()"
      ],
      "metadata": {
        "id": "SFawXgJLfvls"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_and_tags = nltk.pos_tag(sentence)\n",
        "words_and_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuJliO6WfrOq",
        "outputId": "06a0dac0-b602-4364-85d2-aa1f8902f3f6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('cat', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('following', 'VBG'),\n",
              " ('the', 'DT'),\n",
              " ('bird', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('it', 'PRP'),\n",
              " ('flew', 'VBD'),\n",
              " ('by', 'IN')]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word,tag in words_and_tags:\n",
        "  lemma = lemmatizer.lemmatize(word, pos = get_wordnet_pos(tag))\n",
        "  print(word+\" ---> \"+lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQOj9E-bgeOC",
        "outputId": "cabac350-04c9-42a6-d876-5ff5bca83585"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "cat ---> cat\n",
            "was ---> be\n",
            "following ---> follow\n",
            "the ---> the\n",
            "bird ---> bird\n",
            "as ---> a\n",
            "it ---> it\n",
            "flew ---> fly\n",
            "by ---> by\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3sPHwG1g09F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}